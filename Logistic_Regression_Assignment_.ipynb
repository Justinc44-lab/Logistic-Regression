{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Theoretical Questions with Answers\n",
        "\n",
        "#### **1. What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "**Logistic Regression** is a classification algorithm used to predict the probability of a categorical dependent variable. It is mainly used for binary classification (0 or 1, Yes or No).\n",
        "\n",
        "- **Linear Regression** predicts continuous outcomes.\n",
        "- **Logistic Regression** predicts probabilities that are then mapped to binary outcomes using the **sigmoid function**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. What is the mathematical equation of Logistic Regression?**\n",
        "\n",
        "The equation is:\n",
        "\n",
        "\\[\n",
        "P(y = 1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n)}}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( P(y = 1|x) \\) is the probability of the class being 1\n",
        "- \\( \\beta_0 \\) is the intercept\n",
        "- \\( \\beta_1 \\ldots \\beta_n \\) are the coefficients\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Why do we use the Sigmoid function in Logistic Regression?**\n",
        "\n",
        "The **Sigmoid function** maps any real-valued number into the (0, 1) interval, making it ideal for modeling probabilities:\n",
        "\n",
        "\\[\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "\\]\n",
        "\n",
        "It allows us to interpret the output as a probability.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. What is the cost function of Logistic Regression?**\n",
        "\n",
        "The cost function used is the **Log Loss** (binary cross-entropy):\n",
        "\n",
        "\\[\n",
        "J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\right]\n",
        "\\]\n",
        "\n",
        "This penalizes incorrect predictions with higher cost.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. What is Regularization in Logistic Regression? Why is it needed?**\n",
        "\n",
        "**Regularization** adds a penalty to the cost function to reduce model complexity and prevent **overfitting**.\n",
        "\n",
        "Types:\n",
        "- **L1 (Lasso)**: Shrinks some coefficients to zero (feature selection)\n",
        "- **L2 (Ridge)**: Shrinks coefficients towards zero but keeps all features\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Explain the difference between Lasso, Ridge, and Elastic Net regression**\n",
        "\n",
        "- **Lasso (L1)**: Adds \\( \\lambda \\sum |\\theta_j| \\) to cost. Encourages sparsity.\n",
        "- **Ridge (L2)**: Adds \\( \\lambda \\sum \\theta_j^2 \\) to cost. Encourages small weights.\n",
        "- **Elastic Net**: Combines L1 and L2: \\( \\lambda_1 \\sum |\\theta_j| + \\lambda_2 \\sum \\theta_j^2 \\)\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "\n",
        "Use **Elastic Net** when:\n",
        "- You have many correlated features\n",
        "- You want both feature selection (L1) and stability (L2)\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. What is the impact of the regularization parameter (λ) in Logistic Regression?**\n",
        "\n",
        "- **High λ**: Stronger penalty, simpler model, risk of underfitting\n",
        "- **Low λ**: Weaker penalty, more complex model, risk of overfitting\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. What are the key assumptions of Logistic Regression?**\n",
        "\n",
        "1. No multicollinearity\n",
        "2. Linearity of log-odds with independent variables\n",
        "3. Independent observations\n",
        "4. Large sample size for stable estimates\n",
        "\n",
        "---\n",
        "\n",
        "#### **10. What are some alternatives to Logistic Regression for classification tasks?**\n",
        "\n",
        "- Decision Trees\n",
        "- Random Forest\n",
        "- Support Vector Machines (SVM)\n",
        "- Naive Bayes\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "#### **11. What are Classification Evaluation Metrics?**\n",
        "\n",
        "- **Accuracy**\n",
        "- **Precision**\n",
        "- **Recall**\n",
        "- **F1-Score**\n",
        "- **ROC-AUC**\n",
        "- **Confusion Matrix**\n",
        "- **Cohen’s Kappa**\n",
        "- **MCC (Matthews Correlation Coefficient)**\n",
        "\n",
        "---\n",
        "\n",
        "#### **12. How does class imbalance affect Logistic Regression?**\n",
        "\n",
        "Class imbalance can lead to a model biased towards the majority class. Solutions include:\n",
        "- Using **class weights**\n",
        "- **Oversampling** / **Undersampling**\n",
        "- **Synthetic Data Generation (SMOTE)**\n",
        "\n",
        "---\n",
        "\n",
        "#### **13. What is Hyperparameter Tuning in Logistic Regression?**\n",
        "\n",
        "It’s the process of finding the best combination of hyperparameters (e.g., **C**, **penalty**, **solver**) using techniques like **GridSearchCV** or **RandomizedSearchCV**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **14. What are different solvers in Logistic Regression? Which one should be used?**\n",
        "\n",
        "- **liblinear**: good for small datasets\n",
        "- **saga**: supports L1, L2, elasticnet; works with large datasets\n",
        "- **lbfgs**: good for L2 regularization and multiclass\n",
        "- **newton-cg**: good for multiclass but no L1\n",
        "\n",
        "---\n",
        "\n",
        "#### **15. How is Logistic Regression extended for multiclass classification?**\n",
        "\n",
        "1. **One-vs-Rest (OvR)**: Train one classifier per class\n",
        "2. **Softmax (Multinomial)**: Generalizes logistic regression to multiple classes\n",
        "\n",
        "---\n",
        "\n",
        "#### **16. What are the advantages and disadvantages of Logistic Regression?**\n",
        "\n",
        "**Advantages:**\n",
        "- Simple, interpretable\n",
        "- Works well for linearly separable classes\n",
        "\n",
        "**Disadvantages:**\n",
        "- Poor with non-linear relationships\n",
        "- Sensitive to multicollinearity and outliers\n",
        "\n",
        "---\n",
        "\n",
        "#### **17. What are some use cases of Logistic Regression?**\n",
        "\n",
        "- Email spam detection\n",
        "- Credit scoring\n",
        "- Disease diagnosis (e.g., diabetes prediction)\n",
        "- Customer churn prediction\n",
        "- Marketing response prediction\n",
        "\n",
        "---\n",
        "\n",
        "#### **18. What is the difference between Softmax Regression and Logistic Regression?**\n",
        "\n",
        "- **Logistic Regression**: Binary classification using sigmoid\n",
        "- **Softmax Regression**: Multiclass classification using softmax function\n",
        "\n",
        "---\n",
        "\n",
        "#### **19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**\n",
        "\n",
        "- Use **OvR** for simplicity or when interpretability is key\n",
        "- Use **Softmax** for performance and when classes are mutually exclusive\n",
        "\n",
        "---\n",
        "\n",
        "#### **20. How do we interpret coefficients in Logistic Regression?**\n",
        "\n",
        "Each coefficient represents the change in the **log-odds** of the outcome for a one-unit increase in the corresponding predictor.\n",
        "\n",
        "\\[\n",
        "\\text{Odds Ratio} = e^{\\beta_j}\n",
        "\\]\n"
      ],
      "metadata": {
        "id": "hx_gMK_WSI8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypfqebj0TRk_",
        "outputId": "d95fc5d0-ed96-40a8-bb79-48fad59a50a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"L1-Regularized Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOuFQtv2Ulv2",
        "outputId": "aa5b29c6-dafe-4fc8-e3e0-ccae74668dfd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1-Regularized Logistic Regression Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"L2-Regularized Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGB7JqFLVRP3",
        "outputId": "2a67d986-2ce0-47c1-a6ad-2b9d76325a51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-Regularized Logistic Regression Accuracy: 0.956140350877193\n",
            "Model Coefficients: [[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Elastic Net Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ0r5QHCVUaj",
        "outputId": "d4dcd3af-85a3-4f89-afc7-f1b4a0d4e3d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Logistic Regression Accuracy: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "265ouBo7b2vL",
        "outputId": "65c3b362-0c02-4f6a-82cc-fb60d6eb5137"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scwIGovGlEKS",
        "outputId": "bbf1a560-272a-4f9d-b158-4585d406b742"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "print(\"Average Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VcvZUYGlLIt",
        "outputId": "77326556-5dd5-4fd8-fbad-aed96672bea9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = pd.read_csv('your_dataset.csv')  # Replace with actual CSV file\n",
        "X = data.drop('target', axis=1)         # Replace 'target' with actual column name\n",
        "y = data['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "2CV1mWBXlYRU",
        "outputId": "18db05da-3cdd-4973-9a49-09af09edc288"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e63695d58b1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'your_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with actual CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Replace 'target' with actual column name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  9: Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0, scale=4),\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=100, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Accuracy:\", random_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So62zL8BmkrB",
        "outputId": "008f279c-02d4-4809-a92f-2b35e819ca01"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': np.float64(1.8888597006477972), 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy: 0.9604395604395604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10: Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"OvO Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgiNJMvZlsv2",
        "outputId": "8361c686-8583-4036-908a-5019f42dc5f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvO Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11: Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_b6TWiMqpxEF",
        "outputId": "2022ec6a-8528-4baf-e89a-625f055d7125"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12: Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LluhfGOUpycf",
        "outputId": "11caad40-0ce0-4fd3-de91-5f47cb1a4346"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.958904109589041\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.9722222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13: Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X, y = make_classification(n_samples=1000, weights=[0.9, 0.1], random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph3Flfz7pzCF",
        "outputId": "a02a7e7b-a78e-48b4-8e8c-31200ee3f9d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.88      0.92       180\n",
            "           1       0.41      0.75      0.53        20\n",
            "\n",
            "    accuracy                           0.86       200\n",
            "   macro avg       0.69      0.81      0.72       200\n",
            "weighted avg       0.91      0.86      0.88       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14: Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Titanic dataset from online source\n",
        "url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select features and target\n",
        "X = data[['Pclass', 'Sex', 'Age', 'Fare']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Define preprocessing\n",
        "numeric_features = ['Age', 'Fare']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['Sex', 'Pclass']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Create pipeline\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear'))])\n",
        "\n",
        "# Split and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDkLzy2kpzaV",
        "outputId": "6604bbb2-1f52-4710-d738-d579a961ac1d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7528089887640449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15 15: Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Without scaling\n",
        "model_no_scale = LogisticRegression(max_iter=1000)\n",
        "model_no_scale.fit(X_train, y_train)\n",
        "y_pred_no_scale = model_no_scale.predict(X_test)\n",
        "acc_no_scale = accuracy_score(y_test, y_pred_no_scale)\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc_no_scale)\n",
        "print(\"Accuracy with scaling:\", acc_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaEd9JawpzxD",
        "outputId": "4fe4e07b-a7a6-4107-b41c-5aca867479ad"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.956140350877193\n",
            "Accuracy with scaling: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16: Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(\"ROC-AUC Score:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cECxzpiFp0Fh",
        "outputId": "d17819f2-c769-4cb8-884e-539e6cc5b206"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9970520799213888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17: Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with C=0.5:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nERX3-GPp0Yo",
        "outputId": "e5b6bd10-7f67-410f-894b-eb238b53f66f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18: Write a Python program to train Logistic Regression and identify important features based on model coefficients\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X, y)\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': model.coef_[0]\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(\"Top 5 Important Features:\")\n",
        "print(coefficients.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrp1Y_h2p0tR",
        "outputId": "ea6a69b5-ac11-47ef-9c7e-54f6542dcce2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Important Features:\n",
            "            Feature  Coefficient\n",
            "0       mean radius     2.159021\n",
            "20     worst radius     1.268334\n",
            "11    texture error     0.903038\n",
            "12  perimeter error     0.268826\n",
            "1      mean texture     0.114013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19: Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa Score.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen's Kappa Score:\", kappa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpWrm-3Ep1Cd",
        "outputId": "5194bdf2-567e-4bbb-8f63-589e7eb184f6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.9246280991735537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20: Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9a4BIWspp1XX",
        "outputId": "3e2db15b-4f62-422c-fdfc-0c44704b0e8b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQAZJREFUeJzt3XlclWX+//H3YTugbBqbC4W4MZpLYfLAJbVIFHPSacrUXCjN9TclY46YSrZItphWLuW4Td8mUbPG0jDFrFTKcvuO5b6EG7iUoCggnPv3R1/PdAYwIeCA9+v5eNyPh+c6132dz3VlnXf3fZ1zLIZhGAIAADARF2cXAAAAUNUIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQABKNHToUIWFhZXpnE2bNslisWjTpk2VUlNN17VrV3Xt2tX++NixY7JYLFqyZInTagLMigAEVBNLliyRxWKxH56enmrWrJnGjh2rrKwsZ5dX7V0LE9cOFxcX1a1bVz179lR6erqzy6sQWVlZGj9+vCIiIlSrVi3Vrl1bkZGReuGFF3ThwgVnlwfUKG7OLgCAo+eee06NGjVSXl6eNm/erHnz5mnt2rXas2ePatWqVWV1LFiwQDabrUzn3H333bpy5Yo8PDwqqarf1r9/f8XFxamoqEgHDhzQ3Llz1a1bN3377bdq1aqV0+r6vb799lvFxcXp0qVLevTRRxUZGSlJ+u677/TSSy/pyy+/1GeffebkKoGagwAEVDM9e/ZUu3btJEnDhg3TLbfcopkzZ+pf//qX+vfvX+I5ubm5ql27doXW4e7uXuZzXFxc5OnpWaF1lNWdd96pRx991P64c+fO6tmzp+bNm6e5c+c6sbLyu3Dhgvr27StXV1ft3LlTERERDs+/+OKLWrBgQYW8VmX8XQKqI26BAdXcPffcI0k6evSopF/25nh7e+vw4cOKi4uTj4+PBg4cKEmy2WyaNWuWWrZsKU9PTwUHB2vEiBH6+eefi4376aefqkuXLvLx8ZGvr6/uuusu/fOf/7Q/X9IeoGXLlikyMtJ+TqtWrTR79mz786XtAVqxYoUiIyPl5eWlgIAAPfroozp58qRDn2vzOnnypPr06SNvb28FBgZq/PjxKioqKvf6de7cWZJ0+PBhh/YLFy7oqaeeUmhoqKxWq5o0aaIZM2YUu+pls9k0e/ZstWrVSp6engoMDFSPHj303Xff2fssXrxY99xzj4KCgmS1WtWiRQvNmzev3DX/t7ffflsnT57UzJkzi4UfSQoODtbkyZPtjy0Wi5599tli/cLCwjR06FD742u3Xb/44guNHj1aQUFBatiwoVauXGlvL6kWi8WiPXv22Nv27dunP//5z6pbt648PT3Vrl07rV69+vdNGqhkXAECqrlrb9y33HKLva2wsFCxsbHq1KmTXn31VfutsREjRmjJkiWKj4/XX/7yFx09elRvvfWWdu7cqS1bttiv6ixZskSPPfaYWrZsqcTERPn7+2vnzp1KTU3VgAEDSqxj/fr16t+/v+69917NmDFDkrR3715t2bJFTz75ZKn1X6vnrrvuUnJysrKysjR79mxt2bJFO3fulL+/v71vUVGRYmNjFRUVpVdffVUbNmzQa6+9psaNG2vUqFHlWr9jx45JkurUqWNvu3z5srp06aKTJ09qxIgRuvXWW7V161YlJibq9OnTmjVrlr3v448/riVLlqhnz54aNmyYCgsL9dVXX+nrr7+2X6mbN2+eWrZsqT/+8Y9yc3PTxx9/rNGjR8tms2nMmDHlqvvXVq9eLS8vL/35z3/+3WOVZPTo0QoMDNTUqVOVm5urXr16ydvbW8uXL1eXLl0c+qakpKhly5a6/fbbJUnff/+9OnbsqAYNGmjixImqXbu2li9frj59+uiDDz5Q3759K6Vm4HczAFQLixcvNiQZGzZsMM6ePWscP37cWLZsmXHLLbcYXl5exokTJwzDMIwhQ4YYkoyJEyc6nP/VV18Zkoz33nvPoT01NdWh/cKFC4aPj48RFRVlXLlyxaGvzWaz/3nIkCHGbbfdZn/85JNPGr6+vkZhYWGpc/j8888NScbnn39uGIZhFBQUGEFBQcbtt9/u8FqffPKJIcmYOnWqw+tJMp577jmHMe+44w4jMjKy1Ne85ujRo4YkY9q0acbZs2eNzMxM46uvvjLuuusuQ5KxYsUKe9/nn3/eqF27tnHgwAGHMSZOnGi4uroaGRkZhmEYxsaNGw1Jxl/+8pdir/frtbp8+XKx52NjY43w8HCHti5duhhdunQpVvPixYuvO7c6deoYbdq0uW6fX5NkJCUlFWu/7bbbjCFDhtgfX/s716lTp2L/XPv3728EBQU5tJ8+fdpwcXFx+Gd07733Gq1atTLy8vLsbTabzejQoYPRtGnTG64ZqGrcAgOqmZiYGAUGBio0NFSPPPKIvL299eGHH6pBgwYO/f77isiKFSvk5+en++67T+fOnbMfkZGR8vb21ueffy7plys5Fy9e1MSJE4vt17FYLKXW5e/vr9zcXK1fv/6G5/Ldd9/pzJkzGj16tMNr9erVSxEREVqzZk2xc0aOHOnwuHPnzjpy5MgNv2ZSUpICAwMVEhKizp07a+/evXrttdccrp6sWLFCnTt3Vp06dRzWKiYmRkVFRfryyy8lSR988IEsFouSkpKKvc6v18rLy8v+5+zsbJ07d05dunTRkSNHlJ2dfcO1lyYnJ0c+Pj6/e5zSDB8+XK6urg5t/fr105kzZxxuZ65cuVI2m039+vWTJP3000/auHGjHn74YV28eNG+jufPn1dsbKwOHjxY7FYnUF1wCwyoZubMmaNmzZrJzc1NwcHBat68uVxcHP9fxc3NTQ0bNnRoO3jwoLKzsxUUFFTiuGfOnJH0n1tq125h3KjRo0dr+fLl6tmzpxo0aKDu3bvr4YcfVo8ePUo958cff5QkNW/evNhzERER2rx5s0PbtT02v1anTh2HPUxnz5512BPk7e0tb29v++MnnnhCDz30kPLy8rRx40a98cYbxfYQHTx4UP/7v/9b7LWu+fVa1a9fX3Xr1i11jpK0ZcsWJSUlKT09XZcvX3Z4Ljs7W35+ftc9/7f4+vrq4sWLv2uM62nUqFGxth49esjPz08pKSm69957Jf1y+6tt27Zq1qyZJOnQoUMyDENTpkzRlClTShz7zJkzxcI7UB0QgIBqpn379va9JaWxWq3FQpHNZlNQUJDee++9Es8p7c3+RgUFBWnXrl1at26dPv30U3366adavHixBg8erKVLl/6usa/576sQJbnrrrvswUr65YrPrzf8Nm3aVDExMZKk+++/X66urpo4caK6detmX1ebzab77rtPEyZMKPE1rr3B34jDhw/r3nvvVUREhGbOnKnQ0FB5eHho7dq1ev3118v8VQIliYiI0K5du1RQUPC7vmKgtM3kv76CdY3ValWfPn304Ycfau7cucrKytKWLVs0ffp0e59rcxs/frxiY2NLHLtJkyblrheoTAQg4CbRuHFjbdiwQR07dizxDe3X/SRpz549ZX5z8vDwUO/evdW7d2/ZbDaNHj1ab7/9tqZMmVLiWLfddpskaf/+/fZPs12zf/9++/Nl8d577+nKlSv2x+Hh4dft/8wzz2jBggWaPHmyUlNTJf2yBpcuXbIHpdI0btxY69at008//VTqVaCPP/5Y+fn5Wr16tW699VZ7+7VbjhWhd+/eSk9P1wcffFDqVyH8Wp06dYp9MWJBQYFOnz5dptft16+fli5dqrS0NO3du1eGYdhvf0n/WXt3d/ffXEugumEPEHCTePjhh1VUVKTnn3++2HOFhYX2N8Tu3bvLx8dHycnJysvLc+hnGEap458/f97hsYuLi1q3bi1Jys/PL/Gcdu3aKSgoSPPnz3fo8+mnn2rv3r3q1avXDc3t1zp27KiYmBj78VsByN/fXyNGjNC6deu0a9cuSb+sVXp6utatW1es/4ULF1RYWChJevDBB2UYhqZNm1as37W1unbV6tdrl52drcWLF5d5bqUZOXKk6tWrp7/+9a86cOBAsefPnDmjF154wf64cePG9n1M17zzzjtl/jqBmJgY1a1bVykpKUpJSVH79u0dbpcFBQWpa9euevvtt0sMV2fPni3T6wFViStAwE2iS5cuGjFihJKTk7Vr1y51795d7u7uOnjwoFasWKHZs2frz3/+s3x9ffX6669r2LBhuuuuuzRgwADVqVNHu3fv1uXLl0u9nTVs2DD99NNPuueee9SwYUP9+OOPevPNN9W2bVv94Q9/KPEcd3d3zZgxQ/Hx8erSpYv69+9v/xh8WFiYxo0bV5lLYvfkk09q1qxZeumll7Rs2TI9/fTTWr16te6//34NHTpUkZGRys3N1b///W+tXLlSx44dU0BAgLp166ZBgwbpjTfe0MGDB9WjRw/ZbDZ99dVX6tatm8aOHavu3bvbr4yNGDFCly5d0oIFCxQUFFTmKy6lqVOnjj788EPFxcWpbdu2Dt8EvWPHDr3//vuKjo629x82bJhGjhypBx98UPfdd592796tdevWKSAgoEyv6+7urj/96U9atmyZcnNz9eqrrxbrM2fOHHXq1EmtWrXS8OHDFR4erqysLKWnp+vEiRPavXv375s8UFmc+RE0AP9x7SPJ33777XX7DRkyxKhdu3apz7/zzjtGZGSk4eXlZfj4+BitWrUyJkyYYJw6dcqh3+rVq40OHToYXl5ehq+vr9G+fXvj/fffd3idX38MfuXKlUb37t2NoKAgw8PDw7j11luNESNGGKdPn7b3+e+PwV+TkpJi3HHHHYbVajXq1q1rDBw40P6x/t+aV1JSknEj/6m69pHyV155pcTnhw4dari6uhqHDh0yDMMwLl68aCQmJhpNmjQxPDw8jICAAKNDhw7Gq6++ahQUFNjPKywsNF555RUjIiLC8PDwMAIDA42ePXsa27dvd1jL1q1bG56enkZYWJgxY8YMY9GiRYYk4+jRo/Z+5f0Y/DWnTp0yxo0bZzRr1szw9PQ0atWqZURGRhovvviikZ2dbe9XVFRk/O1vfzMCAgKMWrVqGbGxscahQ4dK/Rj89f7OrV+/3pBkWCwW4/jx4yX2OXz4sDF48GAjJCTEcHd3Nxo0aGDcf//9xsqVK29oXoAzWAzjOte8AQAAbkLsAQIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKbDFyGWwGaz6dSpU/Lx8bnur2MDAIDqwzAMXbx4UfXr1y/2e4n/jQBUglOnTik0NNTZZQAAgHI4fvy4GjZseN0+BKAS+Pj4SPplAX19fZ1cDQAAuBE5OTkKDQ21v49fDwGoBNdue/n6+hKAAACoYW5k+wqboAEAgOkQgAAAgOkQgAAAgOkQgAAAgOkQgAAAgOkQgAAAgOkQgAAAgOkQgAAAgOkQgAAAgOkQgAAAgOk4NQB9+eWX6t27t+rXry+LxaKPPvroN8/ZtGmT7rzzTlmtVjVp0kRLliwp1mfOnDkKCwuTp6enoqKitG3btoovHgAA1FhODUC5ublq06aN5syZc0P9jx49ql69eqlbt27atWuXnnrqKQ0bNkzr1q2z90lJSVFCQoKSkpK0Y8cOtWnTRrGxsTpz5kxlTQMAANQwFsMwDGcXIf3yw2Uffvih+vTpU2qfv/3tb1qzZo327Nljb3vkkUd04cIFpaamSpKioqJ011136a233pIk2Ww2hYaG6v/9v/+niRMn3lAtOTk58vPzU3Z2doX+GGpO3lXlXLlaYeMBAFBVvK1u8q/l4ewyrqss79816tfg09PTFRMT49AWGxurp556SpJUUFCg7du3KzEx0f68i4uLYmJilJ6eXuq4+fn5ys/Ptz/Oycmp2ML/z/98/aNeTt1fKWMDAFCZXF0sWjiknbo2D3J2KRWiRgWgzMxMBQcHO7QFBwcrJydHV65c0c8//6yioqIS++zbt6/UcZOTkzVt2rRKqfnX3Fwssrqx7xwAULNcLbKpyGbo+1M5BKCbSWJiohISEuyPc3JyFBoaWuGv88TdjfXE3Y0rfFwAACrThJW7tfy7E84uo0LVqAAUEhKirKwsh7asrCz5+vrKy8tLrq6ucnV1LbFPSEhIqeNarVZZrdZKqRkAAFQ/Nep+THR0tNLS0hza1q9fr+joaEmSh4eHIiMjHfrYbDalpaXZ+wAAADg1AF26dEm7du3Srl27JP3yMfddu3YpIyND0i+3pgYPHmzvP3LkSB05ckQTJkzQvn37NHfuXC1fvlzjxo2z90lISNCCBQu0dOlS7d27V6NGjVJubq7i4+OrdG4AAKD6cuotsO+++07dunWzP762D2fIkCFasmSJTp8+bQ9DktSoUSOtWbNG48aN0+zZs9WwYUP9/e9/V2xsrL1Pv379dPbsWU2dOlWZmZlq27atUlNTi22MBgAA5lVtvgeoOqms7wECAKAmurYJ+unY5hrTrYmzyylVWd6/a9QeIAAAgIpAAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKbj5uwCAABAzVVYZNOl/EJdzCvUpfz/O/IKdTG/ULfWraW2of7OLrFEBCAAAHBDln2boc++z9TF/ws4l/IKdeVqUan9XV0sSk+8R0E+nlVY5Y0hAAEAgOuqW9sqSTr+0xUd/+lKiX083V3kbXWXj6ebvK1u2ns6R4U2Qz/nXiUAAQCAmmd0t8ZqFuwtF4tF3la3X0KOp5t8Pd3lbf3lz+6ujtuK272wXucuFTip4t9GAAIAANfl6+muP93Z0NllVCg+BQYAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEzH6QFozpw5CgsLk6enp6KiorRt27ZS+169elXPPfecGjduLE9PT7Vp00apqakOfZ599llZLBaHIyIiorKnAQAAahCnBqCUlBQlJCQoKSlJO3bsUJs2bRQbG6szZ86U2H/y5Ml6++239eabb+qHH37QyJEj1bdvX+3cudOhX8uWLXX69Gn7sXnz5qqYDgAAqCGcGoBmzpyp4cOHKz4+Xi1atND8+fNVq1YtLVq0qMT+7777riZNmqS4uDiFh4dr1KhRiouL02uvvebQz83NTSEhIfYjICCgKqYDAABqCKcFoIKCAm3fvl0xMTH/KcbFRTExMUpPTy/xnPz8fHl6ejq0eXl5FbvCc/DgQdWvX1/h4eEaOHCgMjIyrltLfn6+cnJyHA4AAHDzcloAOnfunIqKihQcHOzQHhwcrMzMzBLPiY2N1cyZM3Xw4EHZbDatX79eq1at0unTp+19oqKitGTJEqWmpmrevHk6evSoOnfurIsXL5ZaS3Jysvz8/OxHaGhoxUwSAABUS07fBF0Ws2fPVtOmTRURESEPDw+NHTtW8fHxcnH5zzR69uyphx56SK1bt1ZsbKzWrl2rCxcuaPny5aWOm5iYqOzsbPtx/PjxqpgOAABwEqcFoICAALm6uiorK8uhPSsrSyEhISWeExgYqI8++ki5ubn68ccftW/fPnl7eys8PLzU1/H391ezZs106NChUvtYrVb5+vo6HAAA4ObltADk4eGhyMhIpaWl2dtsNpvS0tIUHR193XM9PT3VoEEDFRYW6oMPPtADDzxQat9Lly7p8OHDqlevXoXVDgAAajan3gJLSEjQggULtHTpUu3du1ejRo1Sbm6u4uPjJUmDBw9WYmKivf8333yjVatW6ciRI/rqq6/Uo0cP2Ww2TZgwwd5n/Pjx+uKLL3Ts2DFt3bpVffv2laurq/r371/l8wMAANWTmzNfvF+/fjp79qymTp2qzMxMtW3bVqmpqfaN0RkZGQ77e/Ly8jR58mQdOXJE3t7eiouL07vvvit/f397nxMnTqh///46f/68AgMD1alTJ3399dcKDAys6ukBAIBqymIYhuHsIqqbnJwc+fn5KTs7m/1AAACUQ7sX1uvcpQKte+puNQ/xqZLXLMv7d436FBgAAEBFIAABAADTIQABAADTIQABAADTIQABAADTIQABAADTcer3AAEAgJvflYIinbxwWSd+vqITP19RfqFNf76zofxquTutJgIQAACoNH+ev1UX8wqLtV8tsmlkl8ZOqOgX3AIDAAAVLtjXU5Ls4cfb6qaIEB/V9/ulPefKVafVJnEFCAAAVIJFQ+/Sv09kq56/pxr615Kvl5ssFoue+/gHLdpy1NnlEYAAAEDFC/b1VHALT2eXUSpugQEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANNxegCaM2eOwsLC5OnpqaioKG3btq3UvlevXtVzzz2nxo0by9PTU23atFFqaurvGhMAAJiPUwNQSkqKEhISlJSUpB07dqhNmzaKjY3VmTNnSuw/efJkvf3223rzzTf1ww8/aOTIkerbt6927txZ7jEBAID5ODUAzZw5U8OHD1d8fLxatGih+fPnq1atWlq0aFGJ/d99911NmjRJcXFxCg8P16hRoxQXF6fXXnut3GMCAADzcVoAKigo0Pbt2xUTE/OfYlxcFBMTo/T09BLPyc/Pl6enp0Obl5eXNm/eXO4xr42bk5PjcAAAgJuX0wLQuXPnVFRUpODgYIf24OBgZWZmlnhObGysZs6cqYMHD8pms2n9+vVatWqVTp8+Xe4xJSk5OVl+fn72IzQ09HfODgAAVGdO3wRdFrNnz1bTpk0VEREhDw8PjR07VvHx8XJx+X3TSExMVHZ2tv04fvx4BVUMAACqI6cFoICAALm6uiorK8uhPSsrSyEhISWeExgYqI8++ki5ubn68ccftW/fPnl7eys8PLzcY0qS1WqVr6+vwwEAAG5eTgtAHh4eioyMVFpamr3NZrMpLS1N0dHR1z3X09NTDRo0UGFhoT744AM98MADv3tMAABgHm7OfPGEhAQNGTJE7dq1U/v27TVr1izl5uYqPj5ekjR48GA1aNBAycnJkqRvvvlGJ0+eVNu2bXXy5Ek9++yzstlsmjBhwg2PCQAA4NQA1K9fP509e1ZTp05VZmam2rZtq9TUVPsm5oyMDIf9PXl5eZo8ebKOHDkib29vxcXF6d1335W/v/8NjwkAAGAxDMNwdhHVTU5Ojvz8/JSdnc1+IAAAKtBzH/+gRVuOanTXxprQI6JCxy7L+3eN+hQYAABARSAAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA03F6AJozZ47CwsLk6empqKgobdu27br9Z82apebNm8vLy0uhoaEaN26c8vLy7M8/++yzslgsDkdERERlTwMAANQgbs588ZSUFCUkJGj+/PmKiorSrFmzFBsbq/379ysoKKhY/3/+85+aOHGiFi1apA4dOujAgQMaOnSoLBaLZs6cae/XsmVLbdiwwf7Yzc2p0wQAANWMU68AzZw5U8OHD1d8fLxatGih+fPnq1atWlq0aFGJ/bdu3aqOHTtqwIABCgsLU/fu3dW/f/9iV43c3NwUEhJiPwICAqpiOgAAoIZwWgAqKCjQ9u3bFRMT859iXFwUExOj9PT0Es/p0KGDtm/fbg88R44c0dq1axUXF+fQ7+DBg6pfv77Cw8M1cOBAZWRkVN5EAABAjeO0e0Pnzp1TUVGRgoODHdqDg4O1b9++Es8ZMGCAzp07p06dOskwDBUWFmrkyJGaNGmSvU9UVJSWLFmi5s2b6/Tp05o2bZo6d+6sPXv2yMfHp8Rx8/PzlZ+fb3+ck5NTATMEAADVldM3QZfFpk2bNH36dM2dO1c7duzQqlWrtGbNGj3//PP2Pj179tRDDz2k1q1bKzY2VmvXrtWFCxe0fPnyUsdNTk6Wn5+f/QgNDa2K6QAAACdx2hWggIAAubq6Kisry6E9KytLISEhJZ4zZcoUDRo0SMOGDZMktWrVSrm5uXriiSf0zDPPyMWleJ7z9/dXs2bNdOjQoVJrSUxMVEJCgv1xTk4OIQgAgJuY064AeXh4KDIyUmlpafY2m82mtLQ0RUdHl3jO5cuXi4UcV1dXSZJhGCWec+nSJR0+fFj16tUrtRar1SpfX1+HAwAA3Lyc+vnwhIQEDRkyRO3atVP79u01a9Ys5ebmKj4+XpI0ePBgNWjQQMnJyZKk3r17a+bMmbrjjjsUFRWlQ4cOacqUKerdu7c9CI0fP169e/fWbbfdplOnTikpKUmurq7q37+/0+YJAACqF6cGoH79+uns2bOaOnWqMjMz1bZtW6Wmpto3RmdkZDhc8Zk8ebIsFosmT56skydPKjAwUL1799aLL75o73PixAn1799f58+fV2BgoDp16qSvv/5agYGBVT4/AABQPVmM0u4dmVhOTo78/PyUnZ3N7TAAACrQcx//oEVbjmp018aa0KNif6mhLO/fNepTYAAAABWhXLfAioqKtGTJEqWlpenMmTOy2WwOz2/cuLFCigMAAKgM5QpATz75pJYsWaJevXrp9ttvl8Viqei6AAAAKk25AtCyZcu0fPnyYj9BAQAAUBOUaw+Qh4eHmjRpUtG1AAAAVIlyBaC//vWvmj17dqlfPggAAFCdlesW2ObNm/X555/r008/VcuWLeXu7u7w/KpVqyqkOAAAgMpQrgDk7++vvn37VnQtAAAAVaJcAWjx4sUVXQcAAECV+V0/hXH27Fnt379fktS8eXN+bgIAANQI5doEnZubq8cee0z16tXT3Xffrbvvvlv169fX448/rsuXL1d0jQAAABWqXAEoISFBX3zxhT7++GNduHBBFy5c0L/+9S998cUX+utf/1rRNQIAAFSoct0C++CDD7Ry5Up17drV3hYXFycvLy89/PDDmjdvXkXVBwAAUOHKdQXo8uXLCg4OLtYeFBTELTAAAFDtlSsARUdHKykpSXl5efa2K1euaNq0aYqOjq6w4gAAACpDuW6BzZ49W7GxsWrYsKHatGkjSdq9e7c8PT21bt26Ci0QAACgopUrAN1+++06ePCg3nvvPe3bt0+S1L9/fw0cOFBeXl4VWiAAAEBFK/f3ANWqVUvDhw+vyFoAAACqxA0HoNWrV6tnz55yd3fX6tWrr9v3j3/84+8uDAAAoLLccADq06ePMjMzFRQUpD59+pTaz2KxqKioqCJqAwAAqBQ3HIBsNluJfwYAAKhpyvUx+JJcuHChooYCAACoVOUKQDNmzFBKSor98UMPPaS6deuqQYMG2r17d4UVBwAAUBnKFYDmz5+v0NBQSdL69eu1YcMGpaamqmfPnnr66acrtEAAAICKVq6PwWdmZtoD0CeffKKHH35Y3bt3V1hYmKKioiq0QAAAgIpWritAderU0fHjxyVJqampiomJkSQZhsEnwAAAQLVXritAf/rTnzRgwAA1bdpU58+fV8+ePSVJO3fuVJMmTSq0QAAAgIpWrgD0+uuvKywsTMePH9fLL78sb29vSdLp06c1evToCi0QAACgopUrALm7u2v8+PHF2seNG/e7CwIAAKhs/BQGAAAwHX4KAwAAmA4/hQEAAEynwn4KAwAAoKYoVwD6y1/+ojfeeKNY+1tvvaWnnnrq99YEAABQqcoVgD744AN17NixWHuHDh20cuXKMo01Z84chYWFydPTU1FRUdq2bdt1+8+aNUvNmzeXl5eXQkNDNW7cOOXl5f2uMQEAgLmUKwCdP39efn5+xdp9fX117ty5Gx4nJSVFCQkJSkpK0o4dO9SmTRvFxsbqzJkzJfb/5z//qYkTJyopKUl79+7VwoULlZKSokmTJpV7TAAAYD7lCkBNmjRRampqsfZPP/1U4eHhNzzOzJkzNXz4cMXHx6tFixaaP3++atWqpUWLFpXYf+vWrerYsaMGDBigsLAwde/eXf3793e4wlPWMQEAgPmU64sQExISNHbsWJ09e1b33HOPJCktLU2vvfaaZs2adUNjFBQUaPv27UpMTLS3ubi4KCYmRunp6SWe06FDB/3P//yPtm3bpvbt2+vIkSNau3atBg0aVO4xJSk/P1/5+fn2xzk5OTc0BwAAUDOVKwA99thjys/P14svvqjnn39ekhQWFqZ58+Zp8ODBNzTGuXPnVFRUpODgYIf24OBg7du3r8RzBgwYoHPnzqlTp04yDEOFhYUaOXKk/RZYecaUpOTkZE2bNu2G6gYAADVfuT8GP2rUKJ04cUJZWVnKycnRkSNHbjj8lNemTZs0ffp0zZ07Vzt27NCqVau0Zs0aewgrr8TERGVnZ9uPa790DwAAbk7lugIkSYWFhdq0aZMOHz6sAQMGSJJOnTolX19f+4+jXk9AQIBcXV2VlZXl0J6VlaWQkJASz5kyZYoGDRqkYcOGSZJatWql3NxcPfHEE3rmmWfKNaYkWa1WWa3W36wZAADcHMp1BejHH39Uq1at9MADD2jMmDE6e/asJGnGjBkl/khqSTw8PBQZGam0tDR7m81mU1pamqKjo0s85/Lly3JxcSzZ1dVVkmQYRrnGBAAA5lOuAPTkk0+qXbt2+vnnn+Xl5WVv79u3r0P4+C0JCQlasGCBli5dqr1792rUqFHKzc1VfHy8JGnw4MEOG5p79+6tefPmadmyZTp69KjWr1+vKVOmqHfv3vYg9FtjAgAAlOsW2FdffaWtW7fKw8PDoT0sLEwnT5684XH69euns2fPaurUqcrMzFTbtm2Vmppq38SckZHhcMVn8uTJslgsmjx5sk6ePKnAwED17t1bL7744g2PCQAAYDEMwyjrSXXq1NGWLVvUokUL+fj4aPfu3QoPD9fmzZv14IMPFtuDU9Pk5OTIz89P2dnZ8vX1dXY5AADcNJ77+Act2nJUo7s21oQeERU6dlnev8t1C6x79+4O3/djsVh06dIlJSUlKS4urjxDAgAAVJly3QJ79dVX1aNHD7Vo0UJ5eXkaMGCADh48qICAAL3//vsVXSMAAECFKlcACg0N1e7du5WSkqLdu3fr0qVLevzxxzVw4ECHTdEAAADVUZkD0NWrVxUREaFPPvlEAwcO1MCBAyujLgAAgEpT5j1A7u7uysvLq4xaAAAAqkS5NkGPGTNGM2bMUGFhYUXXAwAAUOnKtQfo22+/VVpamj777DO1atVKtWvXdnh+1apVFVIcAABAZShXAPL399eDDz5Y0bUAAABUiTIFIJvNpldeeUUHDhxQQUGB7rnnHj377LN88gsAANQoZdoD9OKLL2rSpEny9vZWgwYN9MYbb2jMmDGVVRsAAEClKFMA+sc//qG5c+dq3bp1+uijj/Txxx/rvffek81mq6z6AAAAKlyZAlBGRobDT13ExMTIYrHo1KlTFV4YAABAZSlTACosLJSnp6dDm7u7u65evVqhRQEAAFSmMm2CNgxDQ4cOldVqtbfl5eVp5MiRDh+F52PwAACgOitTABoyZEixtkcffbTCigEAAKgKZQpAixcvrqw6AAAAqky5fgoDAACgJiMAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA06kWAWjOnDkKCwuTp6enoqKitG3btlL7du3aVRaLpdjRq1cve5+hQ4cWe75Hjx5VMRUAAFADuDm7gJSUFCUkJGj+/PmKiorSrFmzFBsbq/379ysoKKhY/1WrVqmgoMD++Pz582rTpo0eeughh349evTQ4sWL7Y+tVmvlTQIAANQoTr8CNHPmTA0fPlzx8fFq0aKF5s+fr1q1amnRokUl9q9bt65CQkLsx/r161WrVq1iAchqtTr0q1OnTlVMBwAA1ABODUAFBQXavn27YmJi7G0uLi6KiYlRenr6DY2xcOFCPfLII6pdu7ZD+6ZNmxQUFKTmzZtr1KhROn/+fIXWDgAAai6n3gI7d+6cioqKFBwc7NAeHBysffv2/eb527Zt0549e7Rw4UKH9h49euhPf/qTGjVqpMOHD2vSpEnq2bOn0tPT5erqWmyc/Px85efn2x/n5OSUc0YAAKAmcPoeoN9j4cKFatWqldq3b+/Q/sgjj9j/3KpVK7Vu3VqNGzfWpk2bdO+99xYbJzk5WdOmTav0egEAQPXg1FtgAQEBcnV1VVZWlkN7VlaWQkJCrntubm6uli1bpscff/w3Xyc8PFwBAQE6dOhQic8nJiYqOzvbfhw/fvzGJwEAAGocpwYgDw8PRUZGKi0tzd5ms9mUlpam6Ojo6567YsUK5efn69FHH/3N1zlx4oTOnz+vevXqlfi81WqVr6+vwwEAAG5eTv8UWEJCghYsWKClS5dq7969GjVqlHJzcxUfHy9JGjx4sBITE4udt3DhQvXp00e33HKLQ/ulS5f09NNP6+uvv9axY8eUlpamBx54QE2aNFFsbGyVzAkAAFRvTt8D1K9fP509e1ZTp05VZmam2rZtq9TUVPvG6IyMDLm4OOa0/fv3a/Pmzfrss8+Kjefq6qr//d//1dKlS3XhwgXVr19f3bt31/PPP893AQEAAEnVIABJ0tixYzV27NgSn9u0aVOxtubNm8swjBL7e3l5ad26dRVZHgAAuMk4/RYYAABAVSMAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA06kWAWjOnDkKCwuTp6enoqKitG3btlL7du3aVRaLpdjRq1cvex/DMDR16lTVq1dPXl5eiomJ0cGDB6tiKgAAoAZwegBKSUlRQkKCkpKStGPHDrVp00axsbE6c+ZMif1XrVql06dP2489e/bI1dVVDz30kL3Pyy+/rDfeeEPz58/XN998o9q1ays2NlZ5eXlVNS0AAFCNOT0AzZw5U8OHD1d8fLxatGih+fPnq1atWlq0aFGJ/evWrauQkBD7sX79etWqVcsegAzD0KxZszR58mQ98MADat26tf7xj3/o1KlT+uijj6pwZgAAoLpyagAqKCjQ9u3bFRMTY29zcXFRTEyM0tPTb2iMhQsX6pFHHlHt2rUlSUePHlVmZqbDmH5+foqKiip1zPz8fOXk5DgcAADg5uXUAHTu3DkVFRUpODjYoT04OFiZmZm/ef62bdu0Z88eDRs2zN527byyjJmcnCw/Pz/7ERoaWtapAACAGsTpt8B+j4ULF6pVq1Zq37797xonMTFR2dnZ9uP48eMVVCEAAKiOnBqAAgIC5OrqqqysLIf2rKwshYSEXPfc3NxcLVu2TI8//rhD+7XzyjKm1WqVr6+vwwEAAG5eTg1AHh4eioyMVFpamr3NZrMpLS1N0dHR1z13xYoVys/P16OPPurQ3qhRI4WEhDiMmZOTo2+++eY3xwQAAObg5uwCEhISNGTIELVr107t27fXrFmzlJubq/j4eEnS4MGD1aBBAyUnJzuct3DhQvXp00e33HKLQ7vFYtFTTz2lF154QU2bNlWjRo00ZcoU1a9fX3369KmqaQEAgGrM6QGoX79+Onv2rKZOnarMzEy1bdtWqamp9k3MGRkZcnFxvFC1f/9+bd68WZ999lmJY06YMEG5ubl64okndOHCBXXq1Empqany9PSs9PkAAIDqz2IYhuHsIqqbnJwc+fn5KTs7m/1AAABUoOc+/kGLthzV6K6NNaFHRIWOXZb37xr9KTAAAIDyIAABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTcXoAmjNnjsLCwuTp6amoqCht27btuv0vXLigMWPGqF69erJarWrWrJnWrl1rf/7ZZ5+VxWJxOCIiIip7GgAAoAZxc+aLp6SkKCEhQfPnz1dUVJRmzZql2NhY7d+/X0FBQcX6FxQU6L777lNQUJBWrlypBg0a6Mcff5S/v79Dv5YtW2rDhg32x25uTp0mAACoZpyaDGbOnKnhw4crPj5ekjR//nytWbNGixYt0sSJE4v1X7RokX766Sdt3bpV7u7ukqSwsLBi/dzc3BQSElKptQMAgJrLabfACgoKtH37dsXExPynGBcXxcTEKD09vcRzVq9erejoaI0ZM0bBwcG6/fbbNX36dBUVFTn0O3jwoOrXr6/w8HANHDhQGRkZlToXAABQszjtCtC5c+dUVFSk4OBgh/bg4GDt27evxHOOHDmijRs3auDAgVq7dq0OHTqk0aNH6+rVq0pKSpIkRUVFacmSJWrevLlOnz6tadOmqXPnztqzZ498fHxKHDc/P1/5+fn2xzk5ORU0SwAAUB3VqM0xNptNQUFBeuedd+Tq6qrIyEidPHlSr7zyij0A9ezZ096/devWioqK0m233ably5fr8ccfL3Hc5ORkTZs2rUrmAAAAnM9pt8ACAgLk6uqqrKwsh/asrKxS9+/Uq1dPzZo1k6urq73tD3/4gzIzM1VQUFDiOf7+/mrWrJkOHTpUai2JiYnKzs62H8ePHy/HjAAAQE3htADk4eGhyMhIpaWl2dtsNpvS0tIUHR1d4jkdO3bUoUOHZLPZ7G0HDhxQvXr15OHhUeI5ly5d0uHDh1WvXr1Sa7FarfL19XU4AADAzcup3wOUkJCgBQsWaOnSpdq7d69GjRql3Nxc+6fCBg8erMTERHv/UaNG6aefftKTTz6pAwcOaM2aNZo+fbrGjBlj7zN+/Hh98cUXOnbsmLZu3aq+ffvK1dVV/fv3r/L5AQCA6smpe4D69euns2fPaurUqcrMzFTbtm2Vmppq3xidkZEhF5f/ZLTQ0FCtW7dO48aNU+vWrdWgQQM9+eST+tvf/mbvc+LECfXv31/nz59XYGCgOnXqpK+//lqBgYFVPj8AAFA9WQzDMJxdRHWTk5MjPz8/ZWdnczsMAIAK9NzHP2jRlqMa3bWxJvSo2F9qKMv7t9N/CgMAAKCqEYAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAECVcXe1yOrmIjcXi1PrsBiGYTi1gmooJydHfn5+ys7Olq+vr7PLAQAAN6As799cAQIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKbj5uwCqiPDMCRJOTk5Tq4EAADcqGvv29fex6+HAFSCixcvSpJCQ0OdXAkAACirixcvys/P77p9LMaNxCSTsdlsOnXqlHx8fGSxWCp07JycHIWGhur48ePy9fWt0LHxH6xz1WCdqwbrXDVY56pRmetsGIYuXryo+vXry8Xl+rt8uAJUAhcXFzVs2LBSX8PX15d/waoA61w1WOeqwTpXDda5alTWOv/WlZ9r2AQNAABMhwAEAABMhwBUxaxWq5KSkmS1Wp1dyk2Nda4arHPVYJ2rButcNarLOrMJGgAAmA5XgAAAgOkQgAAAgOkQgAAAgOkQgAAAgOkQgCrBnDlzFBYWJk9PT0VFRWnbtm3X7b9ixQpFRETI09NTrVq10tq1a6uo0pqtLOu8YMECde7cWXXq1FGdOnUUExPzm/9c8Iuy/n2+ZtmyZbJYLOrTp0/lFniTKOs6X7hwQWPGjFG9evVktVrVrFkz/ttxA8q6zrNmzVLz5s3l5eWl0NBQjRs3Tnl5eVVUbc305Zdfqnfv3qpfv74sFos++uij3zxn06ZNuvPOO2W1WtWkSRMtWbKk0uuUgQq1bNkyw8PDw1i0aJHx/fffG8OHDzf8/f2NrKysEvtv2bLFcHV1NV5++WXjhx9+MCZPnmy4u7sb//73v6u48pqlrOs8YMAAY86cOcbOnTuNvXv3GkOHDjX8/PyMEydOVHHlNUtZ1/mao0ePGg0aNDA6d+5sPPDAA1VTbA1W1nXOz8832rVrZ8TFxRmbN282jh49amzatMnYtWtXFVdes5R1nd977z3DarUa7733nnH06FFj3bp1Rr169Yxx48ZVceU1y9q1a41nnnnGWLVqlSHJ+PDDD6/b/8iRI0atWrWMhIQE44cffjDefPNNw9XV1UhNTa3UOglAFax9+/bGmDFj7I+LioqM+vXrG8nJySX2f/jhh41evXo5tEVFRRkjRoyo1DprurKu838rLCw0fHx8jKVLl1ZWiTeF8qxzYWGh0aFDB+Pvf/+7MWTIEALQDSjrOs+bN88IDw83CgoKqqrEm0JZ13nMmDHGPffc49CWkJBgdOzYsVLrvJncSACaMGGC0bJlS4e2fv36GbGxsZVYmWFwC6wCFRQUaPv27YqJibG3ubi4KCYmRunp6SWek56e7tBfkmJjY0vtj/Kt83+7fPmyrl69qrp161ZWmTVeedf5ueeeU1BQkB5//PGqKLPGK886r169WtHR0RozZoyCg4N1++23a/r06SoqKqqqsmuc8qxzhw4dtH37dvttsiNHjmjt2rWKi4urkprNwlnvg/wYagU6d+6cioqKFBwc7NAeHBysffv2lXhOZmZmif0zMzMrrc6arjzr/N/+9re/qX79+sX+pcN/lGedN2/erIULF2rXrl1VUOHNoTzrfOTIEW3cuFEDBw7U2rVrdejQIY0ePVpXr15VUlJSVZRd45RnnQcMGKBz586pU6dOMgxDhYWFGjlypCZNmlQVJZtGae+DOTk5unLliry8vCrldbkCBNN56aWXtGzZMn344Yfy9PR0djk3jYsXL2rQoEFasGCBAgICnF3OTc1msykoKEjvvPOOIiMj1a9fPz3zzDOaP3++s0u7qWzatEnTp0/X3LlztWPHDq1atUpr1qzR888/7+zSUAG4AlSBAgIC5OrqqqysLIf2rKwshYSElHhOSEhImfqjfOt8zauvvqqXXnpJGzZsUOvWrSuzzBqvrOt8+PBhHTt2TL1797a32Ww2SZKbm5v279+vxo0bV27RNVB5/j7Xq1dP7u7ucnV1tbf94Q9/UGZmpgoKCuTh4VGpNddE5VnnKVOmaNCgQRo2bJgkqVWrVsrNzdUTTzyhZ555Ri4uXEOoCKW9D/r6+lba1R+JK0AVysPDQ5GRkUpLS7O32Ww2paWlKTo6usRzoqOjHfpL0vr160vtj/KtsyS9/PLLev7555Wamqp27dpVRak1WlnXOSIiQv/+97+1a9cu+/HHP/5R3bp1065duxQaGlqV5dcY5fn73LFjRx06dMgeMCXpwIEDqlevHuGnFOVZ58uXLxcLOddCp8HPaFYYp70PVuoWaxNatmyZYbVajSVLlhg//PCD8cQTTxj+/v5GZmamYRiGMWjQIGPixIn2/lu2bDHc3NyMV1991di7d6+RlJTEx+BvQFnX+aWXXjI8PDyMlStXGqdPn7YfFy9edNYUaoSyrvN/41NgN6as65yRkWH4+PgYY8eONfbv32988sknRlBQkPHCCy84awo1QlnXOSkpyfDx8THef/9948iRI8Znn31mNG7c2Hj44YedNYUa4eLFi8bOnTuNnTt3GpKMmTNnGjt37jR+/PFHwzAMY+LEicagQYPs/a99DP7pp5829u7da8yZM4ePwddUb775pnHrrbcaHh4eRvv27Y2vv/7a/lyXLl2MIUOGOPRfvny50axZM8PDw8No2bKlsWbNmiquuGYqyzrfdttthqRiR1JSUtUXXsOU9e/zrxGAblxZ13nr1q1GVFSUYbVajfDwcOPFF180CgsLq7jqmqcs63z16lXj2WefNRo3bmx4enoaoaGhxujRo42ff/656guvQT7//PMS/3t7bW2HDBlidOnSpdg5bdu2NTw8PIzw8HBj8eLFlV6nxTC4jgcAAMyFPUAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAcIMsFos++ugjSdKxY8dksVi0a9cup9YEoHwIQABqhKFDh8pischiscjd3V2NGjXShAkTlJeX5+zSANRA/Bo8gBqjR48eWrx4sa5evart27dryJAhslgsmjFjhrNLA1DDcAUIQI1htVoVEhKi0NBQ9enTRzExMVq/fr2kX37ZOzk5WY0aNZKXl5fatGmjlStXOpz//fff6/7775evr698fHzUuXNnHT58WJL07bff6r777lNAQID8/PzUpUsX7dixo8rnCKBqEIAA1Eh79uzR1q1b5eHhIUlKTk7WP/7xD82fP1/ff/+9xo0bp0cffVRffPGFJOnkyZO6++67ZbVatXHjRm3fvl2PPfaYCgsLJUkXL17UkCFDtHnzZn399ddq2rSp4uLidPHiRafNEUDl4RYYgBrjk08+kbe3twoLC5Wfny8XFxe99dZbys/P1/Tp07VhwwZFR0dLksLDw7V582a9/fbb6tKli+bMmSM/Pz8tW7ZM7u7ukqRmzZrZx77nnnscXuudd96Rv7+/vvjiC91///1VN0kAVYIABKDG6Natm+bNm6fc3Fy9/vrrcnNz04MPPqjvv/9ely9f1n333efQv6CgQHfccYckadeuXercubM9/Py3rKwsTZ48WZs2bdKZM2dUVFSky5cvKyMjo9LnBaDqEYAA1Bi1a9dWkyZNJEmLFi1SmzZttHDhQt1+++2SpDVr1qhBgwYO51itVkmSl5fXdcceMmSIzp8/r9mzZ+u2226T1WpVdHS0CgoKKmEmAJyNAASgRnJxcdGkSZOUkJCgAwcOyGq1KiMjQ126dCmxf+vWrbV06VJdvXq1xKtAW7Zs0dy5cxUXFydJOn78uM6dO1epcwDgPGyCBlBjPfTQQ3J1ddXbb7+t8ePHa9y4cVq6dKkOHz6sHTt26M0339TSpUslSWPHjlVOTo4eeeQRfffddzp48KDeffdd7d+/X5LUtGlTvfvuu9q7d6+++eYbDRw48DevGgGoubgCBKDGcnNz09ixY/Xyyy/r6NGjCgwMVHJyso4cOSJ/f3/deeedmjRpkiTplltu0caNG/X000+rS5cucnV1Vdu2bdWxY0dJ0sKFC/XEE0/ozjvvVGhoqKZPn67x48c7c3oAKpHFMAzD2UUAAABUJW6BAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0/n/18v1b1HpCJ4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  21: Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {solver}:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pNZEE8Tp1qu",
        "outputId": "a83756c6-f60b-45f4-e82a-697eaf3bcdbf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear: 0.956140350877193\n",
            "Accuracy with saga: 0.9649122807017544\n",
            "Accuracy with lbfgs: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 22: Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(\"Matthews Correlation Coefficient:\", mcc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL6G_HkAp1_G",
        "outputId": "27849b4d-9ac3-4fff-9bef-d0e0bb35e4f3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient: 0.9252853920667758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 23: Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Raw data\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Standardized data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"Accuracy (raw data):\", acc_raw)\n",
        "print(\"Accuracy (scaled data):\", acc_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6NOOj_Qp2St",
        "outputId": "e59e2e1a-9cee-4c7c-87d7-1b669370e962"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (raw data): 0.956140350877193\n",
            "Accuracy (scaled data): 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24: Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegressionCV(Cs=10, cv=5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Optimal C:\", model.C_[0])\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjzlBD_Gp2jc",
        "outputId": "31949014-012b-4a80-818b-91c132dc78ca"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 1291.5496650148827\n",
            "Accuracy: 0.9824561403508771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 25: Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump, load\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model\n",
        "dump(model, 'logreg_model.joblib')\n",
        "\n",
        "# Load model\n",
        "loaded_model = load('logreg_model.joblib')\n",
        "\n",
        "# Make predictions\n",
        "y_pred = loaded_model.predict(X_test[:5])\n",
        "print(\"Sample predictions:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PdVsersp20u",
        "outputId": "ca4f6dc8-2e37-445c-c085-f4b211dd9db9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample predictions: [1 0 0 1 1]\n"
          ]
        }
      ]
    }
  ]
}